# Content Repurposing Engine

An intelligent AI-powered system that transforms long-form content into multiple platform-specific versions optimized for LinkedIn, Twitter/X, blogs, emails, and more.

## ğŸ¯ Overview

This system uses Groq API for fast AI-powered content generation, FastAPI for the backend API, and Supabase for data persistence. It intelligently analyzes content and generates platform-optimized versions while maintaining the core message and insights.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend UI   â”‚
â”‚  (React/HTML)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI API   â”‚
â”‚   - Upload      â”‚
â”‚   - Process     â”‚
â”‚   - Retrieve    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Simple Job    â”‚
â”‚   Processor     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Extract   â”‚  â”‚
â”‚  â”‚ Analyze   â”‚  â”‚
â”‚  â”‚ Generate  â”‚  â”‚
â”‚  â”‚ Optimize  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Supabase     â”‚
â”‚  - Content DB   â”‚
â”‚  - File Storage â”‚
â”‚  - Analytics    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Features

- **Multi-format Input**: PDF, DOCX, PPT, text, URLs
- **Platform Optimization**: LinkedIn, Twitter/X, Blog, Email sequences
- **Intelligent Analysis**: Extracts key insights, tone, and structure
- **Quality Preservation**: Maintains core message across all versions
- **Fast Processing**: 2-3 minutes for complete repurposing
- **Analytics**: Track performance and engagement

## ğŸ“‹ Prerequisites

- Python 3.11+
- Node.js 18+ (for frontend)
- Supabase account
- OpenAI API key (or other LLM provider)

## ğŸ› ï¸ Tech Stack

- **Backend**: FastAPI, Python 3.11+
- **AI Processing**: Groq API (Llama 3)
- **Database**: Supabase (PostgreSQL)
- **File Storage**: Supabase Storage
- **Document Processing**: PyPDF2, python-docx, BeautifulSoup4
- **LLM**: OpenAI GPT-4 (configurable)

## ğŸ“¦ Installation

See [INSTALLATION.md](./docs/INSTALLATION.md) for detailed setup instructions.

## ğŸ“š Documentation

- [Architecture Overview](./docs/ARCHITECTURE.md)
- [API Documentation](./docs/API.md)
- [Platform Strategies](./docs/PLATFORM_STRATEGIES.md)
- [Database Schema](./docs/DATABASE_SCHEMA.md)

## ğŸ® Quick Start

```bash
# Clone and setup
git clone <repo-url>
cd content-repurposing-engine

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your credentials

# Initialize database
python scripts/init_db.py

# Run the server
uvicorn app.main:app --reload

# Access API docs
# http://localhost:8000/docs
```

## ğŸ“– Usage Example

```python
import requests

# Upload content
response = requests.post(
    "http://localhost:8000/api/v1/content/upload",
    files={"file": open("article.pdf", "rb")},
    data={"platforms": ["linkedin", "twitter", "blog"]}
)

job_id = response.json()["job_id"]

# Check status
status = requests.get(f"http://localhost:8000/api/v1/jobs/{job_id}")

# Get results
results = requests.get(f"http://localhost:8000/api/v1/content/{job_id}/outputs")
```

## ğŸ”‘ Key Components

### 1. Content Extraction
- PDF/DOCX parsing
- URL scraping with readability
- Text preprocessing and cleaning

### 2. Simple Job Processing
- Direct Groq API integration
- Parallel platform generation
- Quality validation gates

### 3. Platform Generators
- LinkedIn: Professional tone, hashtags, CTAs
- Twitter: Thread structure, hooks, engagement
- Blog: SEO optimization, structure
- Email: Sequence building, storytelling

### 4. Quality Assurance
- Character limit validation
- Tone consistency checking
- Key insight preservation
- Platform best practices

## ğŸ“Š Project Structure

```
content-repurposing-engine/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/            # API endpoints
â”‚   â”‚   â””â”€â”€ dependencies.py    # Shared dependencies
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â”‚   â””â”€â”€ security.py        # Auth & security
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ extraction/        # Content extraction
â”‚   â”‚   â””â”€â”€ generators/        # Platform generators
â”‚   â”œâ”€â”€ models/                # Pydantic models
â”‚   â””â”€â”€ db/
â”‚       â”œâ”€â”€ supabase.py        # Supabase client
â”‚       â””â”€â”€ repositories/      # Data access layer
â”œâ”€â”€ docs/                      # Documentation
â”œâ”€â”€ tests/                     # Test suite
â”œâ”€â”€ scripts/                   # Utility scripts
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app tests/

# Run specific test
pytest tests/test_generators.py
```

## ğŸš€ Deployment

See [DEPLOYMENT.md](./docs/DEPLOYMENT.md) for production deployment guide.

## ğŸ“ˆ Performance

- Average processing time: 90-120 seconds
- Supports files up to 50MB
- Concurrent job processing
- Rate limiting and caching

## ğŸ¤ Contributing

Contributions welcome! Please read [CONTRIBUTING.md](./CONTRIBUTING.md) first.

## ğŸ“„ License

MIT License - see [LICENSE](./LICENSE) file for details.

## ğŸ†˜ Support

- Documentation: [docs/](./docs/)
- Issues: GitHub Issues
- Email: support@example.com

---

Built with â¤ï¸ using FastAPI, Groq API, and Supabase
